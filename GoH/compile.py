# -*- coding: utf-8 -*-import osimport sysfrom bs4 import BeautifulSoupimport requestsimport redef get_html_page(url):    """Uses the requests library to get HTML content from URL"""    r = requests.get(url)    return r.textdef get_local_corpus_data(directory, title):    wd = os.listdir(directory)    listing = []    for each in wd:        if each.startswith(title):            if not each.startswith('.'):                _id = each                listing.append(_id[:-4])    return listingdef filename_from_html(content):    """Uses Beautiful Soup to extract the PDF ids from the HTML page.     This script is customized to the structure of the archive pages at    http://documents.adventistarchives.org/Periodicals/Forms/AllFolders.aspx.    Args:        content (str): Content is retrieved from a URL using the `get_html_page`             function.    """    soup = BeautifulSoup(content, "lxml")    buttons = soup.find_all('td', class_="ms-vb-title")    pdfIDArray = []    for each in buttons:        links = each.find('a')        pdfID = links.get_text()        pdfIDArray.append(pdfID)    return pdfIDArraydef generate_url(last_title, title):    """    This function generates a new URL for iterating through the periodical titles.     """    return "http://documents.adventistarchives.org/Periodicals/Forms/AllItems.aspx?Paged=TRUE&p_SortBehavior=0&p_FileLeafRef={}%2epdf&RootFolder=%2fPeriodicals%2f{}".format(last_title, title)def check_pagination(content):    soup = BeautifulSoup(content, "lxml")    if soup.find_all('td', class_="ms-paging"):        return True    else:        print("No pagination available on page")        return Falsedef check_last_record(pdfIDArray):    last = pdfIDArray[-1]    split_title = last.split('-')    title_date = split_title[0]    date = re.findall(r'[0-9]+', title_date)    year = date[0][:4]    if int(year) < 1921:        return True    else:        return Falsedef check_year(pdfID):    """Uses regex to check the year from the PDF filename.    Args:        pdfID (str): The filename of the PDF object, formatted as             PREFIXYYYYMMDD-V00-00    """    split_title = pdfID.split('-')    title_date = split_title[0]    date = re.findall(r'[0-9]+', title_date)    year = date[0][:4]    if int(year) < 1921:        return True    else:        return Falsedef get_next_url(content, file_list, title):    if check_last_record(file_list):        last_title = file_list[-1]        new_url = generate_url(last_title, title)        return (new_url)    else:        print("Last record ({}) is after 1920".format(last_title))        return Falsedef process_url(url, pdfIDs, title):    """    get baseurl results    - if next page option        - record last title        - if last title is before 1920            - get results            - if next page option                - if last title before 1920                    - get next url    """    print("Processing {}".format(url))    content = get_html_page(url)    file_list = filename_from_html(content)    pdfIDs.append(file_list)    if check_pagination(content) and check_last_record(file_list):        url = get_next_url(content, file_list, title)        process_url(url, pdfIDs, title)    else:        print("Completed all pages in range.")